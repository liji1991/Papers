# 3D视觉引导纠偏技术文档

## 目录

1. [概述](#概述)
2. [系统架构](#系统架构)
3. [前置准备](#前置准备)
   - [示教拍照位与安装位](#示教拍照位与安装位)
   - [手眼标定](#手眼标定)
4. [模板制作流程](#模板制作流程)
5. [视觉引导纠偏流程](#视觉引导纠偏流程)
6. [应用场景](#应用场景)
7. [数学原理](#数学原理)
8. [注意事项与最佳实践](#注意事项与最佳实践)

---

## 概述

3D视觉引导纠偏是工业机器人应用中的核心技术之一，用于解决工件来料位置偏差或取料位置偏差问题。通过3D视觉系统获取工件的实际位姿，与预设的模板位姿进行比对，计算出偏差量，从而引导机械臂精确到达目标位置。

### 核心目标

- **消除工件位置偏差**：补偿工件放置位置的随机性
- **提高定位精度**：通过迭代引导减小系统误差
- **实现柔性生产**：适应不同批次工件的位置变化

---

## 系统架构

```
┌─────────────────────────────────────────────────────────────┐
│                      3D视觉引导系统                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│   ┌──────────┐    ┌──────────┐    ┌──────────────────┐     │
│   │ 3D相机   │───▶│ 视觉处理 │───▶│ 位姿计算与纠偏   │     │
│   └──────────┘    └──────────┘    └──────────────────┘     │
│        │                                    │               │
│        ▼                                    ▼               │
│   ┌────────────────┐                ┌──────────────┐       │
│   │ 2D图片+深度图  │                │ 机械臂控制器 │       │
│   └────────────────┘                └──────────────┘       │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 前置准备

### 示教拍照位与安装位

#### 1. 拍照位示教

拍照位是机械臂携带相机（眼在手上）或相机固定观测（眼在手外）时，能够完整清晰拍摄工件的位置。

**示教步骤：**

1. 将标准工件放置于工作台标准位置
2. 手动移动机械臂，调整相机视角
3. 确保工件完整处于相机视野内
4. 确保成像质量满足特征提取要求
5. 记录当前机械臂TCP相对于Base的6D位姿 `T_photo`

**注意事项：**
- 拍照位应避免光线反射和遮挡
- 工件特征区域应处于相机最佳工作距离
- 建议预留一定的视野冗余（工件占视野60%-80%为宜）

#### 2. 安装位示教

安装位是机械臂执行装配或放置动作的目标位置。

**示教步骤：**

1. 在无视觉引导情况下，手动将机械臂移动到能正确完成安装的位置
2. 记录当前TCP相对于Base的6D位姿 `T_install`
3. 验证该位置能够正确完成安装动作

---

### 手眼标定

手眼标定是建立相机坐标系与机械臂坐标系之间转换关系的过程，是视觉引导的基础。

#### 眼在手上（Eye-in-Hand）

相机安装在机械臂末端执行器上，随机械臂运动。

```
┌────────────────────────────────────────┐
│            眼在手上配置                 │
│                                        │
│    Base ──┬── Link1 ── Link2 ── ...   │
│           │                            │
│           └── TCP ── Camera            │
│                                        │
│    标定目标：求解 T_cam2tcp            │
│    （相机坐标系到TCP坐标系的变换）      │
└────────────────────────────────────────┘
```

**标定原理：**

$$AX = XB$$

其中：
- $A = T_{tcp2base}^{(i)} \cdot (T_{tcp2base}^{(j)})^{-1}$ ：两次拍照间机械臂的相对运动
- $B = T_{cam2target}^{(i)} \cdot (T_{cam2target}^{(j)})^{-1}$ ：两次拍照间相机观测到的标定板相对运动
- $X = T_{cam2tcp}$ ：待求解的手眼变换矩阵

**标定步骤：**

1. 将标定板固定于工作台，确保位置稳定
2. 移动机械臂到第1个拍照位置，记录 `T_tcp2base_1`，拍照获取 `T_cam2target_1`
3. 移动机械臂到第2个拍照位置，记录 `T_tcp2base_2`，拍照获取 `T_cam2target_2`
4. 重复步骤3，采集10-20组不同位姿数据
5. 使用手眼标定算法（如Tsai-Lenz、Park、Horaud等）求解 `T_cam2tcp`

**位姿采集建议：**
- 每次移动应包含平移和旋转分量
- 旋转角度建议覆盖 ±30° 范围
- 避免仅绕单一轴旋转
- 各位姿应均匀分布在工作空间内

---

#### 眼在手外（Eye-to-Hand）

相机固定安装在工作台或支架上，不随机械臂运动。

```
┌────────────────────────────────────────┐
│            眼在手外配置                 │
│                                        │
│    Camera (固定)                       │
│        │                               │
│        ▼ 观测                          │
│    Base ──┬── Link1 ── Link2 ── TCP   │
│           │                            │
│           └── 标定板(装在TCP上)        │
│                                        │
│    标定目标：求解 T_cam2base           │
│    （相机坐标系到基坐标系的变换）       │
└────────────────────────────────────────┘
```

**标定原理：**

$$AX = ZB$$

其中：
- $A = T_{tcp2base}^{(i)}$ ：机械臂TCP在基坐标系下的位姿
- $B = T_{cam2target}^{(i)}$ ：相机观测到的标定板位姿
- $X = T_{target2tcp}$ ：标定板到TCP的固定变换
- $Z = T_{cam2base}$ ：待求解的相机到基坐标系变换

**标定步骤：**

1. 将标定板固定安装在机械臂TCP上
2. 移动机械臂到第1个位置，记录 `T_tcp2base_1`，拍照获取 `T_cam2target_1`
3. 移动机械臂到不同位置，重复采集10-20组数据
4. 使用手眼标定算法求解 `T_cam2base`

---

## 模板制作流程

模板是视觉引导的参考基准，代表工件处于标准位置时的特征信息。

### 通用流程

```
┌─────────────────────────────────────────────────────────┐
│                     模板制作流程                         │
│                                                         │
│  1. 放置标准工件 ──▶ 2. 移动到拍照位 ──▶ 3. 拍照采集    │
│                                                         │
│  4. 提取特征 ──▶ 5. 保存模板数据 ──▶ 6. 验证模板        │
└─────────────────────────────────────────────────────────┘
```

### 详细步骤

#### 步骤1：放置标准工件

将工件放置于标准位置，确保：
- 工件位置可重复
- 在无视觉引导情况下，机械臂能正确完成作业
- 该位置作为所有后续纠偏的参考基准

#### 步骤2：移动到拍照位

将机械臂移动到预先示教的拍照位 `T_photo_template`。

#### 步骤3：拍照采集

触发3D相机采集，获取工件的3D数据（点云或深度图）。

#### 步骤4：提取特征并保存模板

根据引导方法的不同，模板数据分为两类：

---

### 方法A：点云配准法

**适用场景：** 工件形状复杂、特征丰富

**模板数据：**
- 工件点云 `P_template`
- 拍照位位姿 `T_photo_template`（TCP2Base）

**特征提取：**
```
输入：原始点云数据
处理：
  1. 点云预处理（滤波、降采样）
  2. 提取工件ROI区域
  3. 可选：计算点云特征描述子（FPFH、SHOT等）
输出：模板点云 P_template
```

---

### 方法B：坐标系建立法

**适用场景：** 工件具有明确的几何特征（平面、圆孔、边缘等）

**模板数据：**
- 工件坐标系 `Frame_template`（相对于相机坐标系）
- 拍照位位姿 `T_photo_template`（TCP2Base）

**特征提取：**
```
输入：原始点云/图像数据
处理：
  1. 提取几何特征（平面、圆心、边缘点等）
  2. 基于特征建立工件坐标系
     - 例如：平面法向量为Z轴，两孔连线为X轴
输出：工件坐标系 Frame_template
```

---

## 视觉引导纠偏流程

### 整体流程图

```
┌─────────────────────────────────────────────────────────────────────────┐
│                          视觉引导纠偏流程                                │
│                                                                         │
│  ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────────┐      │
│  │移动到    │───▶│ 拍照采集 │───▶│ 特征提取 │───▶│ 计算偏差矩阵 │      │
│  │拍照位    │    │          │    │          │    │              │      │
│  └──────────┘    └──────────┘    └──────────┘    └──────────────┘      │
│                        ▲                                │               │
│                        │                                ▼               │
│                        │                         ┌──────────┐          │
│                        │                         │ 收敛判断 │          │
│                        │                         └──────────┘          │
│                        │                          │        │           │
│                        │                     未收敛│        │已收敛     │
│                        │                          ▼        │           │
│                        │                   ┌──────────┐    │           │
│                        │                   │ 迭代引导 │    │           │
│                        │                   │ 到新位置 │    │           │
│                        │                   └──────────┘    │           │
│                        │                          │        │           │
│                        └──────────────────────────┘        │           │
│                                                            ▼           │
│                                                   ┌───────────────┐    │
│                                                   │ 计算最终纠偏  │    │
│                                                   │ 执行安装动作  │    │
│                                                   └───────────────┘    │
└─────────────────────────────────────────────────────────────────────────┘
```

### 详细步骤

#### 步骤1：移动到拍照位

将机械臂移动到示教的拍照位，记录当前TCP相对于Base的6D位姿：

$$T_{start} = T_{tcp2base}^{current}$$

#### 步骤2：拍照与特征提取

触发相机采集，根据所选方法提取工件特征。

#### 步骤3：计算偏差矩阵

**方法A - 点云配准：**

使用ICP（Iterative Closest Point）或其变体算法，将当前点云 `P_current` 与模板点云 `P_template` 进行配准：

$$T_{match} = ICP(P_{current}, P_{template})$$

其中 $T_{match}$ 为4×4齐次变换矩阵，表示当前工件相对于模板工件的位姿偏差。

**方法B - 坐标系匹配：**

计算当前工件坐标系 `Frame_current` 与模板坐标系 `Frame_template` 之间的变换关系：

$$T_{match} = Frame_{template} \cdot Frame_{current}^{-1}$$

#### 步骤4：迭代引导（关键步骤）

由于手眼标定存在误差，单次引导可能无法精确到达目标位置，需要进行迭代引导。

**迭代引导算法：**

```
初始化：
  T_current = T_start  // 当前拍照位
  iteration = 0
  max_iterations = 5
  convergence_threshold = 0.1mm / 0.01°

循环：
  while iteration < max_iterations:
    1. 在当前位置拍照
    2. 提取特征，计算 T_match
    
    3. 判断收敛：
       if ||T_match - I|| < convergence_threshold:
         break  // 已收敛，退出循环
    
    4. 计算引导增量（根据手眼配置）：
       // 眼在手上：
       T_delta = T_cam2tcp^(-1) · T_match · T_cam2tcp
       
       // 眼在手外：
       T_delta = T_cam2base^(-1) · T_match · T_cam2base
    
    5. 更新拍照位：
       T_current = T_current · T_delta
    
    6. 移动机械臂到新位置 T_current
    
    iteration += 1

输出：
  T_end = T_current  // 收敛后的拍照位
```

#### 步骤5：记录纠偏结果

迭代收敛后，记录最终的拍照位：

$$T_{end} = T_{tcp2base}^{converged}$$

此时我们获得了从初始拍照位到收敛拍照位的总偏差：

$$T_{offset} = T_{start}^{-1} \cdot T_{end}$$

#### 步骤6：应用纠偏到安装位

将纠偏量应用到安装位置。根据手眼配置的不同，纠偏公式有所区别：

##### 情况A：仅眼在手上（Eye-in-Hand）

当偏差在基坐标系下表示时（来料位置偏差），纠偏公式为：

$$T_{install}^{corrected} = T_{end} \cdot T_{start}^{-1} \cdot T_{install}^{template}$$

**公式解释：**
- $T_{start}$：初始拍照位的TCP2Base位姿
- $T_{end}$：迭代引导收敛后的TCP2Base位姿
- $T_{end} \cdot T_{start}^{-1}$：表示在基坐标系下的位姿偏差变换
- 左乘偏差矩阵，将安装位在基坐标系下进行变换

##### 情况B：仅眼在手外（Eye-to-Hand）

当偏差在工具坐标系下表示时（夹持姿态偏差），纠偏公式为：

$$T_{install}^{corrected} = T_{install}^{template} \cdot T_{start}^{-1} \cdot T_{end}$$

**公式解释：**
- $T_{start}^{-1} \cdot T_{end}$：表示在工具坐标系下的位姿偏差变换
- 右乘偏差矩阵，将安装位在工具坐标系下进行变换

##### 情况C：双重纠偏（眼在手上 + 眼在手外）

当同时存在来料偏差和夹持偏差时，需要组合两次纠偏：

$$T_{install}^{corrected} = T_{end1} \cdot T_{start1}^{-1} \cdot T_{install}^{template} \cdot T_{start2}^{-1} \cdot T_{end2}$$

**公式解释：**
- $(T_{start1}, T_{end1})$：眼在手上阶段的起止位姿（来料纠偏）
- $(T_{start2}, T_{end2})$：眼在手外阶段的起止位姿（夹持纠偏）
- 先左乘来料偏差（基坐标系下），再右乘夹持偏差（工具坐标系下）

##### 参考代码实现

```cpp
std::vector<double> one_camera_dock(
    const std::vector<double> &start, 
    const std::vector<double> &end, 
    const std::vector<double> &dock, 
    bool bias_in_base)  // true: 眼在手上, false: 眼在手外
{
    cv::Affine3d start_aff = toAffine3(start);
    cv::Affine3d end_aff = toAffine3(end);
    cv::Affine3d dock_aff = toAffine3(dock);
    cv::Affine3d result;

    if(bias_in_base)  // 眼在手上：偏差在基坐标系
    {
        result = end_aff * start_aff.inv() * dock_aff;
    }
    else  // 眼在手外：偏差在工具坐标系
    {
        result = dock_aff * start_aff.inv() * end_aff;
    }
    return toStdVector(result);
}

// 双重纠偏
std::vector<double> dual_camera_dock(
    const std::vector<double> &start1, const std::vector<double> &end1,  // 眼在手上
    const std::vector<double> &start2, const std::vector<double> &end2,  // 眼在手外
    const std::vector<double> &dock)
{
    cv::Affine3d start1_aff = toAffine3(start1);
    cv::Affine3d end1_aff = toAffine3(end1);
    cv::Affine3d start2_aff = toAffine3(start2);
    cv::Affine3d end2_aff = toAffine3(end2);
    cv::Affine3d dock_aff = toAffine3(dock);
    
    cv::Affine3d result = end1_aff * start1_aff.inv() * dock_aff 
                        * start2_aff.inv() * end2_aff;
    return toStdVector(result);
}
```

---

## 应用场景

### 场景一：来料偏差纠偏（眼在手上）

**适用情况：** 工件放置位置不固定，需要机械臂主动寻找工件位置

```
┌─────────────────────────────────────────────────────────────┐
│                  来料偏差纠偏（眼在手上）                    │
│                                                             │
│   相机随机械臂移动，主动观测工件                            │
│                                                             │
│   ┌─────────┐                     ┌─────────┐              │
│   │  工件   │  ← 位置不确定 →     │  工件   │              │
│   │ (实际)  │                     │ (模板)  │              │
│   └─────────┘                     └─────────┘              │
│       ▲                               ▲                    │
│       │                               │                    │
│   ┌───┴───┐                       ┌───┴───┐                │
│   │ Camera│ ← 机械臂携带 →        │ Camera│                │
│   └───────┘                       └───────┘                │
│                                                             │
│   应用：上料工位、传送带取件、AGV对接等                     │
└─────────────────────────────────────────────────────────────┘
```

**工作流程：**

1. 机械臂移动到预设拍照位（可能偏离工件）
2. 相机拍照，检测工件实际位置
3. 计算工件相对于模板的偏差
4. 迭代引导机械臂，使相机对准工件（与模板位置关系一致）
5. 记录 `T_start` 和 `T_end`
6. 纠偏后执行取料/加工动作

---

### 场景二：取料偏差纠偏（眼在手外）

**适用情况：** 机械臂携带工件，但放置目标位置需要精确定位

```
┌─────────────────────────────────────────────────────────────┐
│                  取料偏差纠偏（眼在手外）                    │
│                                                             │
│   相机固定，观测机械臂携带的工件                            │
│                                                             │
│   ┌─────────┐ (固定)                                       │
│   │ Camera  │ ─────────────────────┐                       │
│   └─────────┘                      │ 观测                  │
│                                    ▼                       │
│                              ┌──────────┐                  │
│                              │ 机械臂   │                  │
│                              │ +工件    │                  │
│                              └──────────┘                  │
│                                    │                       │
│                                    ▼                       │
│                              ┌──────────┐                  │
│                              │ 目标位置 │ ← 需要精确放置   │
│                              └──────────┘                  │
│                                                             │
│   应用：精密装配、PCB插件、轴孔对接等                       │
└─────────────────────────────────────────────────────────────┘
```

**工作流程：**

1. 机械臂抓取工件后移动到拍照位
2. 固定相机拍照，检测工件在机械臂上的实际位姿
3. 计算工件相对于模板姿态的偏差
4. 迭代引导机械臂，使工件姿态与模板一致
5. 记录 `T_start` 和 `T_end`
6. 纠偏后执行安装/放置动作

---

### 场景三：双重纠偏（眼在手上 + 眼在手外）

**适用情况：** 来料位置和安装位置都存在偏差，需要两次视觉引导

```
┌─────────────────────────────────────────────────────────────┐
│                      双重纠偏流程                            │
│                                                             │
│   阶段1：眼在手上（取料纠偏）                               │
│   ┌─────────────────────────────────┐                      │
│   │ 工件位置偏差 → 视觉定位 → 取料  │                      │
│   └─────────────────────────────────┘                      │
│                    │                                        │
│                    ▼ 获得 (T_start1, T_end1)               │
│                                                             │
│   阶段2：眼在手外（放料纠偏）                               │
│   ┌─────────────────────────────────┐                      │
│   │ 夹持姿态偏差 → 视觉校正 → 安装  │                      │
│   └─────────────────────────────────┘                      │
│                    │                                        │
│                    ▼ 获得 (T_start2, T_end2)               │
│                                                             │
│   最终纠偏公式：                                            │
│   T_final = T_end1 · T_start1⁻¹ · T_dock · T_start2⁻¹ · T_end2│
└─────────────────────────────────────────────────────────────┘
```

**典型应用：**

- 汽车零部件装配
- 电子元器件精密贴装
- 航空航天部件组装

**工作流程：**

1. **第一阶段（眼在手上）**：
   - 机械臂移动到取料拍照位，记录 `T_start1`
   - 相机检测工件实际位置
   - 迭代引导，记录收敛后的 `T_end1`
   - 执行取料动作

2. **第二阶段（眼在手外）**：
   - 机械臂携带工件移动到放料拍照位，记录 `T_start2`
   - 固定相机检测工件姿态
   - 迭代引导，记录收敛后的 `T_end2`

3. **综合纠偏**：
   - 计算最终安装位置：`T_final = T_end1 · T_start1⁻¹ · T_dock · T_start2⁻¹ · T_end2`
   - 执行安装动作

---

## 数学原理

### 坐标系定义

| 符号 | 含义 |
|------|------|
| $T_{tcp2base}$ | TCP坐标系相对于机械臂基坐标系的变换 |
| $T_{cam2tcp}$ | 相机坐标系相对于TCP坐标系的变换（眼在手上） |
| $T_{cam2base}$ | 相机坐标系相对于基坐标系的变换（眼在手外） |
| $T_{obj2cam}$ | 工件坐标系相对于相机坐标系的变换 |
| $T_{match}$ | 当前工件与模板工件之间的配准变换 |

### 6D位姿表示

位姿通常表示为6个自由度：$(x, y, z, rx, ry, rz)$

- $(x, y, z)$：平移分量
- $(rx, ry, rz)$：旋转分量（欧拉角或轴角表示）

齐次变换矩阵形式：

$$T = \begin{bmatrix} R_{3×3} & t_{3×1} \\ 0_{1×3} & 1 \end{bmatrix}$$

### 眼在手上的引导公式

相机坐标系下的偏差转换到TCP坐标系：

$$T_{delta}^{tcp} = T_{cam2tcp}^{-1} \cdot T_{match} \cdot T_{cam2tcp}$$

更新后的TCP位姿：

$$T_{tcp2base}^{new} = T_{tcp2base}^{current} \cdot T_{delta}^{tcp}$$

### 眼在手外的引导公式

相机坐标系下的偏差转换到基坐标系：

$$T_{delta}^{base} = T_{cam2base}^{-1} \cdot T_{match} \cdot T_{cam2base}$$

更新后的TCP位姿：

$$T_{tcp2base}^{new} = T_{delta}^{base} \cdot T_{tcp2base}^{current}$$

### 最终纠偏公式

**眼在手上（偏差在基坐标系）：**

$$T_{install}^{corrected} = T_{end} \cdot T_{start}^{-1} \cdot T_{install}^{template}$$

**眼在手外（偏差在工具坐标系）：**

$$T_{install}^{corrected} = T_{install}^{template} \cdot T_{start}^{-1} \cdot T_{end}$$

**双重纠偏（眼在手上 + 眼在手外）：**

$$T_{install}^{corrected} = T_{end1} \cdot T_{start1}^{-1} \cdot T_{install}^{template} \cdot T_{start2}^{-1} \cdot T_{end2}$$

展开理解：
- **眼在手上**：$T_{end} \cdot T_{start}^{-1}$ 左乘，表示在基坐标系下平移和旋转
- **眼在手外**：$T_{start}^{-1} \cdot T_{end}$ 右乘，表示在工具坐标系下平移和旋转
- **双重纠偏**：左乘来料偏差，右乘夹持偏差，综合两次视觉引导结果

---

## 注意事项与最佳实践

### 手眼标定

1. **标定精度**：手眼标定精度直接影响引导精度，建议标定RMS误差 < 0.5mm
2. **重新标定时机**：
   - 相机安装位置调整后
   - 机械臂碰撞或维护后
   - 精度明显下降时
3. **标定数据采集**：
   - 位姿数量：建议15-20组
   - 位姿分布：覆盖工作空间，避免奇异位置

### 模板制作

1. **模板质量**：
   - 选择特征丰富的工件区域
   - 确保点云完整、无遮挡
   - 记录模板制作时的环境条件

2. **多模板管理**：
   - 不同工件类型使用不同模板
   - 定期验证模板有效性

### 迭代引导

1. **收敛条件设置**：
   - 位置阈值：0.05-0.5mm（根据精度要求）
   - 角度阈值：0.01-0.1°
   
2. **最大迭代次数**：
   - 通常3-5次即可收敛
   - 超过次数未收敛应报警

3. **异常处理**：
   - 配准失败：检查光照、遮挡
   - 无法收敛：检查标定精度
   - 位姿突变：可能存在误匹配

### 系统集成

1. **通信延迟**：考虑视觉处理和通信延迟对节拍的影响
2. **安全措施**：设置合理的位姿变化限制，防止碰撞
3. **日志记录**：记录每次引导的详细数据，便于问题追溯

---

## 附录

### A. 常用配准算法

| 算法 | 特点 | 适用场景 |
|------|------|----------|
| ICP | 经典算法，需要良好初值 | 初始偏差较小 |
| NDT | 对噪声鲁棒 | 室外场景、大场景 |
| Super4PCS | 无需初值 | 初始偏差较大 |
| 基于特征的配准 | 速度快，精度依赖特征 | 特征明显的工件 |

### B. 常用手眼标定算法

| 算法 | 论文 | 特点 |
|------|------|------|
| Tsai-Lenz | 1989 | 经典两步法 |
| Park | 1994 | 基于李群理论 |
| Horaud | 1995 | 分离旋转和平移 |
| Daniilidis | 1999 | 对偶四元数方法 |

### C. 参考代码框架

```python
class VisionGuidance:
    def __init__(self, hand_eye_type: str):
        """
        初始化视觉引导系统
        :param hand_eye_type: 'eye_in_hand' 或 'eye_to_hand'
        """
        self.hand_eye_type = hand_eye_type
        self.T_cam2tcp = None  # 眼在手上的手眼矩阵
        self.T_cam2base = None  # 眼在手外的手眼矩阵
        self.template = None
        
    def create_template(self, point_cloud, T_photo):
        """制作模板"""
        self.template = {
            'point_cloud': point_cloud,
            'T_photo': T_photo
        }
        
    def compute_match(self, current_cloud):
        """计算配准矩阵"""
        T_match = icp_registration(
            current_cloud, 
            self.template['point_cloud']
        )
        return T_match
        
    def iterative_guidance(self, robot, camera, max_iter=5, threshold=0.1):
        """迭代引导"""
        T_start = robot.get_tcp_pose()
        T_current = T_start.copy()
        
        for i in range(max_iter):
            # 拍照并配准
            cloud = camera.capture()
            T_match = self.compute_match(cloud)
            
            # 检查收敛
            if self.is_converged(T_match, threshold):
                break
                
            # 计算引导增量
            T_delta = self.compute_delta(T_match)
            
            # 更新位姿
            T_current = T_current @ T_delta
            robot.move_to(T_current)
            
        T_end = robot.get_tcp_pose()
        return T_start, T_end
        
    def apply_correction(self, T_install, T_start, T_end):
        """应用纠偏到安装位"""
        T_offset = np.linalg.inv(T_start) @ T_end
        T_install_corrected = T_install @ T_offset
        return T_install_corrected
```

---

## 版本历史

| 版本 | 日期 | 修改内容 |
|------|------|----------|
| v1.0 | 2026-01-13 | 初始版本 |

---

*本文档为3D视觉引导纠偏技术参考文档，涵盖系统配置、流程说明及数学原理。*
